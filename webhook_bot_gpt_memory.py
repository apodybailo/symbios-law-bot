import os
import json
import logging
from datetime import datetime
from openai import OpenAI

# üîê –ö–ª—é—á API
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=OPENAI_API_KEY)

# üìÅ –§–∞–π–ª –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –ø–∞–º º—è—Ç—ñ
MEMORY_FILE = "memory.json"

# üîä –õ–æ–≥—É–≤–∞–Ω–Ω—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("symbios-law-memory")

# üß† –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –≤ –ø–∞–º º—è—Ç—å
def remember(query: str, reply: str, source="telegram", tags=None):
    entry = {
        "timestamp": datetime.now().isoformat(),
        "query": query,
        "reply": reply,
        "source": source,
        "tags": tags or []
    }

    if not os.path.exists(MEMORY_FILE):
        with open(MEMORY_FILE, "w") as f:
            json.dump([], f)

    with open(MEMORY_FILE, "r") as f:
        data = json.load(f)

    data.append(entry)

    with open(MEMORY_FILE, "w") as f:
        json.dump(data, f, indent=2)

# üîé –ü–æ—à—É–∫ –≤ –ø–∞–º º—è—Ç—ñ (–æ–ø—Ü—ñ–π–Ω–æ)
def memory_lookup(query: str):
    if not os.path.exists(MEMORY_FILE):
        return ""

    with open(MEMORY_FILE, "r") as f:
        data = json.load(f)

    # –ü–æ—à—É–∫ –æ—Å—Ç–∞–Ω–Ω—å–æ–≥–æ —Å—Ö–æ–∂–æ–≥–æ –∑–∞–ø–∏—Ç—É (–ø—Ä–æ—Å—Ç–∏–π —Ñ—ñ–ª—å—Ç—Ä)
    for item in reversed(data):
        if query.lower() in item["query"].lower():
            return item["reply"]

    return ""

# ü§ñ –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è GPT-–≤—ñ–¥–ø–æ–≤—ñ–¥—ñ + –∑–∞–ø–∏—Å —É –ø–∞–º º—è—Ç—å
def generate_gpt_with_memory(user_input: str, context: str = "") -> str:
    try:
        prompt = f"–ê–Ω–∞–ª—ñ–∑—É–π —é—Ä–∏–¥–∏—á–Ω–∏–π –¥–æ–∫—É–º–µ–Ω—Ç:\n–ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}\n–ó–∞–ø–∏—Ç: {user_input}"

        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "–¢–∏ —é—Ä–∏–¥–∏—á–Ω–∏–π –∞–Ω–∞–ª—ñ—Ç–∏–∫. –í—ñ–¥–ø–æ–≤—ñ–¥–∞–π —á—ñ—Ç–∫–æ –π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–æ."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=800
        )

        reply = response.choices[0].message.content.strip()
        remember(user_input, reply)
        return reply

    except Exception as e:
        logger.error(f"‚ùå GPT error: {e}")
        return "GPT –Ω–µ –≤—ñ–¥–ø–æ–≤—ñ–≤ —á–µ—Ä–µ–∑ –ø–æ–º–∏–ª–∫—É."
